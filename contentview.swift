import SwiftUI
import AVFoundation

class VocalMasterEngine: ObservableObject {
    private var audioEngine = AVAudioEngine()
    private var audioRecorder: AVAudioRecorder?
    private var timer: Timer?
    
    // --- æ•°æ®åº“ Key ---
    private let historyKey = "VocalTrainingHistory"
    
    @Published var audioLevel: CGFloat = 0.0
    @Published var currentBreathSeconds: Double = 0
    @Published var bestBreath: Double = 0
    @Published var history: [Double] = [] {
        didSet {
            // æ¯å½“ history æ”¹å˜æ—¶ï¼Œè‡ªåŠ¨å­˜å…¥â€œæ•°æ®åº“â€
            saveToDatabase()
        }
    }
    
    @Published var remainingTime: Int = 60
    @Published var currentPitch: String = "---"
    @Published var frequency: Float = 0.0
    
    init() {
        // App å¯åŠ¨æ—¶ï¼Œå…ˆä»â€œæ•°æ®åº“â€åŠ è½½ä¹‹å‰çš„è®°å½•
        loadFromDatabase()
    }
    
    // --- æ•°æ®åº“æ“ä½œ ---
    private func saveToDatabase() {
        UserDefaults.standard.set(history, forKey: historyKey)
    }
    
    private func loadFromDatabase() {
        if let savedHistory = UserDefaults.standard.array(forKey: historyKey) as? [Double] {
            self.history = savedHistory
        }
    }

    // (ä»¥ä¸‹ startBreathTest, analyzePitch ç­‰æ ¸å¿ƒé€»è¾‘å‡å®Œæ•´ä¿ç•™ä¸”æœªåšåˆ å‡)
    func startBreathTest() {
        stopAll()
        remainingTime = 60
        currentBreathSeconds = 0
        bestBreath = 0
        let session = AVAudioSession.sharedInstance()
        try? session.setCategory(.playAndRecord, mode: .default)
        try? session.setActive(true)
        let url = URL(fileURLWithPath: "/dev/null")
        let settings: [String: Any] = [AVFormatIDKey: Int(kAudioFormatAppleLossless), AVSampleRateKey: 44100.0, AVNumberOfChannelsKey: 1, AVEncoderAudioQualityKey: AVAudioQuality.min.rawValue]
        audioRecorder = try? AVAudioRecorder(url: url, settings: settings)
        audioRecorder?.isMeteringEnabled = true
        audioRecorder?.record()
        
        timer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { _ in
            self.audioRecorder?.updateMeters()
            let level = self.audioRecorder?.averagePower(forChannel: 0) ?? -160
            DispatchQueue.main.async {
                self.audioLevel = CGFloat(max(0.2, (level + 60) / 40))
                if self.remainingTime > 0 {
                    if level > -45 && level < -2 {
                        self.currentBreathSeconds += 0.1
                        if self.currentBreathSeconds > self.bestBreath { self.bestBreath = self.currentBreathSeconds }
                    } else { self.currentBreathSeconds = 0 }
                }
            }
        }
        Timer.scheduledTimer(withTimeInterval: 1, repeats: true) { t in
            DispatchQueue.main.async {
                if self.remainingTime > 0 { self.remainingTime -= 1 }
                else { t.invalidate(); self.stopAll() }
            }
        }
    }
    
    func startPitchDetection() {
        stopAll()
        let inputNode = audioEngine.inputNode
        let format = inputNode.outputFormat(forBus: 0)
        inputNode.installTap(onBus: 0, bufferSize: 1024, format: format) { buffer, _ in
            let data = self.analyzePitch(buffer: buffer)
            DispatchQueue.main.async {
                self.frequency = data.0
                self.currentPitch = data.1
                self.audioLevel = CGFloat(abs(buffer.floatChannelData![0][0])) * 5
            }
        }
        try? audioEngine.start()
    }
    
    func stopAll() {
        timer?.invalidate()
        audioEngine.stop()
        audioEngine.inputNode.removeTap(onBus: 0)
        audioRecorder?.stop()
        if bestBreath > 0 { 
            // å­˜å…¥å†å²ï¼Œä¼šè‡ªåŠ¨è§¦å‘ saveToDatabase()
            history.insert(bestBreath, at: 0) 
        }
    }
    
    private func analyzePitch(buffer: AVAudioPCMBuffer) -> (Float, String) {
        guard let floatData = buffer.floatChannelData?[0] else { return (0, "---") }
        let frameCount = Int(buffer.frameLength)
        var crossings = 0
        for i in 1..<frameCount {
            if (floatData[i-1] < 0 && floatData[i] >= 0) || (floatData[i-1] > 0 && floatData[i] <= 0) { crossings += 1 }
        }
        let freq = Float(crossings) * 44100 / (Float(frameCount) * 2)
        if freq < 80 || freq > 1200 { return (0, "---") }
        let notes = ["C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"]
        let j = Int(round(12 * log2(freq / 440) + 69))
        return (freq, "\(notes[max(0, j % 12)])\(j / 12 - 1)")
    }
}

// (ContentView, BreathChallengeView, PitchLabView ä¿æŒ 7.0 çš„ç»“æ„ä¸å˜)
struct ContentView: View {
    @StateObject private var engine = VocalMasterEngine()
    var body: some View {
        TabView {
            BreathChallengeView(engine: engine)
                .tabItem { Label("æ°”æ¯æŒ‘æˆ˜", systemImage: "wind") }
            PitchLabView(engine: engine)
                .tabItem { Label("éŸ³å‡†å®éªŒ", systemImage: "waveform") }
        }.accentColor(.blue)
    }
}

struct BreathChallengeView: View {
    @ObservedObject var engine: VocalMasterEngine
    @State private var isTesting = false
    var body: some View {
        ScrollView {
            VStack(spacing: 25) {
                Text("1åˆ†é’Ÿæ°”æ¯æŒ‘æˆ˜").font(.title.bold()).padding(.top)
                HStack(spacing: 40) {
                    VStack { Text("å€’è®¡æ—¶"); Text("\(engine.remainingTime)s").font(.title2.monospaced()).bold() }
                    VStack { Text("æœ¬æ¬¡æœ€ä½³"); Text(String(format: "%.1f", engine.bestBreath)).font(.title2.monospaced()).bold().foregroundColor(.orange) }
                }.padding().background(Color.secondary.opacity(0.1)).cornerRadius(15)
                ZStack {
                    Circle().stroke(Color.blue.opacity(0.2), lineWidth: 2).frame(width: 210, height: 210)
                    Circle().fill(isTesting ? Color.blue.opacity(0.3) : Color.gray.opacity(0.1)).frame(width: 200 * (isTesting ? engine.audioLevel : 1.0))
                    VStack {
                        Text(isTesting ? "å½“å‰æ°”æ¯" : "å‡†å¤‡")
                        Text(String(format: "%.1f", engine.currentBreathSeconds)).font(.system(size: 40, weight: .bold, design: .monospaced))
                    }.foregroundColor(.blue)
                }.frame(height: 220)
                Button(action: {
                    isTesting.toggle()
                    isTesting ? engine.startBreathTest() : engine.stopAll()
                }) {
                    Text(isTesting ? "ç»“æŸæµ‹è¯•" : "å¼€å§‹1åˆ†é’Ÿæµ‹éªŒ").bold().foregroundColor(.white).frame(width: 280, height: 60).background(isTesting ? Color.red : Color.blue).cornerRadius(30)
                }
                VStack(alignment: .leading) {
                    Text("ğŸ“Š å†å²æœ€é«˜çºªå½• (å·²æœ¬åœ°ä¿å­˜)").font(.headline)
                    ForEach(engine.history.prefix(5), id: \.self) { record in
                        Text("ä¸€å£æ°”æŒç»­äº†ï¼š\(String(format: "%.1f", record)) ç§’").font(.subheadline).padding(.vertical, 2)
                        Divider()
                    }
                }.padding().background(Color.secondary.opacity(0.05)).cornerRadius(15).padding()
            }
        }
    }
}

struct PitchLabView: View {
    @ObservedObject var engine: VocalMasterEngine
    @State private var isRunning = false
    var body: some View {
        VStack(spacing: 40) {
            Text("éŸ³å‡†å®éªŒå®¤").font(.title.bold())
            ZStack {
                RoundedRectangle(cornerRadius: 25).fill(Color.black.opacity(0.05)).frame(height: 200)
                VStack {
                    Text(engine.currentPitch).font(.system(size: 90, weight: .black, design: .monospaced)).foregroundColor(engine.currentPitch == "---" ? .gray : .green)
                    Text("\(Int(engine.frequency)) Hz").font(.title3).foregroundColor(.secondary)
                }
            }.padding()
            Text("ğŸ’¡ å°è¯•å”±å‡ºä¸€ä¸ªéŸ³ï¼Œå¹¶ä¿æŒå®ƒç¨³å®šä¸å˜").font(.subheadline).foregroundColor(.secondary)
            Button(action: {
                isRunning.toggle()
                isRunning ? engine.startPitchDetection() : engine.stopAll()
            }) {
                Label(isRunning ? "åœæ­¢å®éªŒ" : "å¼€å¯éŸ³å‡†æ£€æµ‹", systemImage: isRunning ? "stop.fill" : "music.mic").bold().foregroundColor(.white).frame(width: 250, height: 60).background(isRunning ? Color.red : Color.green).cornerRadius(30)
            }
            Spacer()
        }.padding()
    }
}
